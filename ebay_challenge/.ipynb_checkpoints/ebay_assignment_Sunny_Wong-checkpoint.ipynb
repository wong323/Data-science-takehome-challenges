{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EBAY Assignment - by Sunny Wong\n",
    "\n",
    "A private (non-business) seller who has just sold an item on eBay may be particularly receptive to a marketing message to buy on eBay. After all, the seller just had a positive selling experience and is in a good mood with respect to eBay, and he just made some money that's burning a hole in his pocket. \n",
    "\n",
    "By contract, eBay sends several transactional email messages for each successful auction\n",
    "\n",
    "Due to their transactional nature, these emails have a high open rate and are thus a perfect candidate for including a buying-focused marketing message.\n",
    "\n",
    "Against this background, your business partner has asked you whether you think there's potential in including a buying marketing message in transactional emails. The high-level question she asks is: “Do you think sellers who just sold an item will be responsive to a buying marketing message, and if yes, which sellers should we target?”.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem breakdown and summary\n",
    "\n",
    "The high level problem comes down to build a predictive model to see which seller be purchasing after a sell. And identifying those sellers be likely to be responsive to a marketing message. In the following I will illustrate the high level steps taken.\n",
    "\n",
    "### Part A) Data  Processing\n",
    "\n",
    "- data exploratory and any data assumptions \n",
    "- data cleaning (dealing with any null values)\n",
    "- data engineering\n",
    "\n",
    "### Part B) Modelling\n",
    "\n",
    "- After the data transformation step, we now have a dataframe ready to build our predictive model\n",
    "- will create a simple model as baseline (decision tree)\n",
    "- build more advance models (such as random forest and gradient boosting) to beat the baseline model\n",
    "- use grid search and cross validation to find optimal hyperparameters\n",
    "- evaluate against test set\n",
    "- discussion on model results\n",
    "\n",
    "### Part C) Insights generated and possible improvement dicussions\n",
    "\n",
    "- insights from models\n",
    "- areas of possible improvement\n",
    "\n",
    "### To take this even further I will discuss the use of experimentation to see if marketing message are effective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A Data Processing Summary\n",
    "\n",
    "- took a look at data before starting the problem\n",
    "- generated target label for next step using after_7d_value\n",
    "- created data_transfomer class with 2 parameters \n",
    "- created new feature based on the difference of original/final sell price (i think it be a good predictor)\n",
    "- drop nulls (ONLY because there was so relatively little of them), also provide alternatives if there was a lot of nulls\n",
    "- prep_df function also use pd.dummie to handle categorial variables\n",
    "- drop unneed columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some common packages for data processing\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sunny.wong2\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2785: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# load data - change path of data file to replciate results\n",
    "path = r'C:\\Users\\sunny.wong2\\JupyterNotebook\\ebay assignment\\Test1.csv'\n",
    "# need list of column names to help read the csv\n",
    "column_names = ['seller',\n",
    "                'buyer_segment',\n",
    "                'full_category',\n",
    "                'category',\n",
    "                'auction_duration',\n",
    "                'start_price',\n",
    "                'total_bids',\n",
    "                'first_2d_bids',\n",
    "                'last_2d_bids',\n",
    "                'final_price',\n",
    "                'final_price_cat_pctl',\n",
    "                'last_7d_searches',\n",
    "                'last_7d_item_views',\n",
    "                'last_7d_purchases',\n",
    "                'last_2d_searches',\n",
    "                'last_2d_item_views',\n",
    "                'last_2d_purchases',\n",
    "                'after_7d_value',\n",
    "                'after_7d_purchases'\n",
    "                ]\n",
    "df = pd.read_csv(path, sep=';', header=None, names=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a transformer class to hold any feature transformation functions here \n",
    "class data_transformer(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.amount_consider_as_responsive = 0\n",
    "        self.perc_consider_as_significant_gain = 0.2\n",
    "    \n",
    "    # want generate label using whether responsive (1 is responsive)\n",
    "    def generate_label(self, y):\n",
    "        if y > self.amount_consider_as_responsive:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    # want to find price difference between start and final price, \n",
    "    # idea is seller more likely buy stuff if made more money\n",
    "    def price_difference_gain_or_loss(self, y):\n",
    "        if y > self.perc_consider_as_significant_gain:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "dt = data_transformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# generate label\n",
    "df['responsive_label'] = df['after_7d_value'].apply(dt.generate_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will give a rate of increase/decrease from original sell price to final price\n",
    "df['sell_price_difference_percentage'] = (df['final_price']-df['start_price'])/df['start_price']\n",
    "df['sell_price_difference_significant'] = df['sell_price_difference_percentage'].apply(dt.price_difference_gain_or_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "11935\n",
      "3215\n"
     ]
    }
   ],
   "source": [
    "# this shows full_category and category has many classes - actually dropped it after playing with the model\n",
    "print(len(df['buyer_segment'].unique()))\n",
    "print(len(df['full_category'].unique()))\n",
    "print(len(df['category'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "seller                                0\n",
       "buyer_segment                        97\n",
       "full_category                        97\n",
       "category                             97\n",
       "auction_duration                     97\n",
       "start_price                          97\n",
       "total_bids                           97\n",
       "first_2d_bids                        97\n",
       "last_2d_bids                         97\n",
       "final_price                          97\n",
       "final_price_cat_pctl                 97\n",
       "last_7d_searches                     97\n",
       "last_7d_item_views                   97\n",
       "last_7d_purchases                    97\n",
       "last_2d_searches                     97\n",
       "last_2d_item_views                   97\n",
       "last_2d_purchases                    97\n",
       "after_7d_value                       97\n",
       "after_7d_purchases                   97\n",
       "responsive_label                      0\n",
       "sell_price_difference_percentage     97\n",
       "sell_price_difference_significant     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this data is actually really nice with very litter null values, below is a count of nulls in each column\n",
    "# so a simple dropna would do for this assignment\n",
    "df.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(axis=0, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# although not needed for this assignment since so little data have null values - but always safe to have ways to deal with\n",
    "# null values, below are 2 simple ways to deal with it (for categorial and numerical variables) when we dealing with a bigger\n",
    "# dataset with more possible nulls\n",
    "def prep_df(input_df):\n",
    "    \n",
    "    prepped_df = input_df.copy()\n",
    "\n",
    "    # replace null values with not_known in these categorical variables\n",
    "    columns = ['buyer_segment']\n",
    "    for c in columns:\n",
    "        prepped_df[c] = prepped_df[c].fillna('not_known')\n",
    "    \n",
    "    # a simple way to deal with NaN in these days difference features is to replace with the mean\n",
    "    columns = [ 'auction_duration',\n",
    "                'start_price',\n",
    "                'total_bids',\n",
    "                'first_2d_bids',\n",
    "                'last_2d_bids',\n",
    "                'final_price',\n",
    "                'final_price_cat_pctl',\n",
    "                'last_7d_searches',\n",
    "                'last_7d_item_views',\n",
    "                'last_7d_purchases',\n",
    "                'last_2d_searches',\n",
    "                'last_2d_item_views',\n",
    "                'last_2d_purchases']\n",
    "    for c in columns:\n",
    "        prepped_df[c] = prepped_df[c].replace(np.NaN, df[c].mean())\n",
    "        \n",
    "    prepped_df = pd.get_dummies(prepped_df)\n",
    "    return prepped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only columns considered for modelling\n",
    "# note seller is removed since is meaningless\n",
    "# 'full_category' and 'category' are removed since is too sparse, over 10k and 3k classes of it\n",
    "# 'after_7d_value' and 'after_7d_purchases' are removed since responsive_label be our target\n",
    "column_names = [\n",
    "                'buyer_segment',\n",
    "                'auction_duration',\n",
    "                'start_price',\n",
    "                'total_bids',\n",
    "                'first_2d_bids',\n",
    "                'last_2d_bids',\n",
    "                'final_price',\n",
    "                'final_price_cat_pctl',\n",
    "                'last_7d_searches',\n",
    "                'last_7d_item_views',\n",
    "                'last_7d_purchases',\n",
    "                'last_2d_searches',\n",
    "                'last_2d_item_views',\n",
    "                'last_2d_purchases',\n",
    "                'sell_price_difference_percentage',\n",
    "                'sell_price_difference_significant',\n",
    "                'responsive_label'\n",
    "                ]\n",
    "df = df[column_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06538217709625621\n"
     ]
    }
   ],
   "source": [
    "# just to get an idea of the class distribution between responsive or not\n",
    "r = len(df.loc[(df['responsive_label'] == 1)]) / len(df)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fairly important finding - a very small subset of sellers end up buying something after 7 days.\n",
    "\n",
    "This is important because it will drive how we evaulate our metric later - recall rate will be much more important rather than just looking at accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B) Modelling Summary\n",
    "\n",
    "\n",
    "- After the data transformation step, we now have a dataframe ready to build our predictive model\n",
    "- will create a simple model as baseline (decision tree)\n",
    "- build more advance models (such as random forest and gradient boosting) to beat the baseline model\n",
    "- use grid search and cross validation to find optimal hyperparameters\n",
    "- evaluate against test set\n",
    "- discussion of models results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import typical ml and metrics packages\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection  import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import f1_score, confusion_matrix, precision_score, recall_score, accuracy_score\n",
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X is our predictors, y is the label we want to predict\n",
    "y = df['responsive_label']\n",
    "X = df.drop(['responsive_label'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "695633\n",
      "695633\n"
     ]
    }
   ],
   "source": [
    "# sanity check to see if y and X have same number of rows\n",
    "print(len(y))\n",
    "print(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use function below to prepare our X dataframe for scikit learn models\n",
    "X_prepped = prep_df(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function first splits into train and test, then do cross validation grid search on the train set \n",
    "# to identify best hyperparamters, using the best_fit model to validate against test set\n",
    "def train_model_with_cv(model, params, X, y):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "    # Use Train data to parameter selection in a Grid Search\n",
    "    gs_clf = GridSearchCV(model, params, n_jobs=1, cv=5)\n",
    "    gs_clf = gs_clf.fit(X_train, y_train)\n",
    "    model = gs_clf.best_estimator_\n",
    "\n",
    "    # Use best model and test data for final evaluation\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    _f1 = f1_score(y_test, y_pred, average='micro')\n",
    "    _confusion = confusion_matrix(y_test, y_pred).ravel()\n",
    "    _accuracy = accuracy_score(y_test, y_pred)\n",
    "    _precision = precision_score(y_test, y_pred)\n",
    "    _recall = recall_score(y_test, y_pred)\n",
    "    _statistics = {'f1_score': _f1,\n",
    "                   'confusion_matrix': 'tn, fp, fn, tp' + str(_confusion),\n",
    "                   'accuracy': _accuracy,\n",
    "                   'precision': _precision,\n",
    "                   'recall': _recall\n",
    "                   }\n",
    "\n",
    "    return model, _statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1_score': 0.9463275236431593, 'confusion_matrix': 'tn, fp, fn, tp[212264   2325   9996   4974]', 'accuracy': 0.9463275236431593, 'precision': 0.6814632141389232, 'recall': 0.3322645290581162}\n"
     ]
    }
   ],
   "source": [
    "# baseline model using decision tree model\n",
    "clf = DecisionTreeClassifier()\n",
    "param_grid = {\"max_depth\": [10, 15, 20],\n",
    "              \"min_impurity_decrease\": [0],\n",
    "              \"criterion\": [\"gini\"],\n",
    "              \"min_samples_split\": [50],\n",
    "              \"min_samples_leaf\": [50],\n",
    "              \"max_features\": [None]\n",
    "              }\n",
    "\n",
    "dt_model , stats = train_model_with_cv(clf, param_grid, X_prepped, y)\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1_score': 0.9477781311122631, 'confusion_matrix': 'tn, fp, fn, tp[213203   1386  10602   4368]', 'accuracy': 0.9477781311122631, 'precision': 0.7591240875912408, 'recall': 0.29178356713426856}\n"
     ]
    }
   ],
   "source": [
    "# random forest model\n",
    "# note running the grid may take a long time, may consider testing less combinatons of hyperparamters\n",
    "clf = RandomForestClassifier()\n",
    "param_grid = {\"n_estimators\": [100, 150],\n",
    "                  \"max_depth\": [3, 8, 12],\n",
    "                  \"max_features\": [\"auto\", \"sqrt\"],\n",
    "                  \"min_samples_split\": [30, 75],\n",
    "                  \"min_samples_leaf\": [30, 75],\n",
    "                  \"bootstrap\": [True],\n",
    "                  \"criterion\": [\"gini\"]\n",
    "              }\n",
    "\n",
    "rf_model , stats = train_model_with_cv(clf, param_grid, X_prepped, y)\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1_score': 0.9557063761385962, 'confusion_matrix': 'tn, fp, fn, tp[213388   1201   8967   6003]', 'accuracy': 0.9557063761385962, 'precision': 0.8332870627429206, 'recall': 0.40100200400801606}\n"
     ]
    }
   ],
   "source": [
    "# gradient boosting model\n",
    "# note running the grid may take a long time, may consider testing less combinatons of hyperparamters\n",
    "clf = XGBClassifier()\n",
    "param_grid = {\"learning_rate\": [0.1],\n",
    "              \"n_estimators\": [100, 150],  # Number of estimators\n",
    "              \"max_depth\": [3, 8, 15],  # maximum depth of decision trees\n",
    "              \"colsample_bytree\": [0.33, 0.66],   # Criterion for splitting\n",
    "              \"subsample\": [0.5, 0.8, 1]\n",
    "             }\n",
    "\n",
    "\n",
    "gb_model , stats = train_model_with_cv(clf, param_grid, X_prepped, y)\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the models I tested performed about the same, with XGBoost performing the best in terms of Recall rate.\n",
    "\n",
    "Remember the accuracy metric isnt the most important because of the class imbalance (because if I only guess not responsive i would've got 94% accuracy) \n",
    "\n",
    "Below talked about a few possible ways to improve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C) Insights generated and possible improvement dicussions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using trained random forest model, can take advantage of its feature importances to see which features are strong predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_important_list = sorted(zip(map(lambda x: round(x, 4), rf_model.feature_importances_), list(X_prepped)), reverse=True)\n",
    "feature_important_list_top5 = feature_important_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.3084, 'last_7d_purchases'), (0.1828, 'last_7d_item_views'), (0.1455, 'last_2d_item_views'), (0.1243, 'last_2d_purchases'), (0.0614, 'last_7d_searches')]\n"
     ]
    }
   ],
   "source": [
    "# show top 5 features from feature important list\n",
    "print(feature_important_list_top5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insights to Leverage\n",
    "\n",
    "The main factor that is best at predicting whether someone who purchase after selling is whether they did a last_7d_purchase and last_7d_item_views. Therefore Ebay should those sellers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Possible ideas for model improvement\n",
    "\n",
    "- Dimensionality reduction, use feature selection and PCA to reduce feature space\n",
    "- Want to consider binning certain variables\n",
    "- Scaling be needed if want to use algorthms like SVM or KNN\n",
    "- include in new features if possible\n",
    "\n",
    "Just want to add a comment about unit testing (did not do for this assignment) - ideally would want to have unit tests for each of the functions wrote to ensure is behaving the way is intended"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimentation \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Experimentation metrics\n",
    "\n",
    "##### To take this even further I will discuss the use of experimentation to see which type of marketing message are more effective.\n",
    "\n",
    "Given the feature has been proposed by the Ebay Team to increase seller's incentive to buy after selling, the key measure of success should reflect an increase in the proportion of responsive seller. \n",
    "\n",
    "    - I would define the KPI as the average number of purchases after selling per seller.\n",
    "\n",
    "In addition, we want to to track these metrics at the seller level\n",
    "\n",
    "    i) average views of other products (are sellers considering purchasing?)\n",
    "    ii) average revenue per seller (since Ebay's marketing email maybe annoying to non-responsive sellers, is this feature worthwhile)\n",
    "    iii) open rate of these email (making sure the new feature won't cause sellers to not open the transactional email)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Experimentation plan\n",
    "\n",
    "Suppose that sellers are exposed to one of two options at 4pm.\n",
    "\n",
    "    - No special message \n",
    "    - Get a marketing message\n",
    "    \n",
    "We will refer these 2 groups of drivers to control group, and test group.\n",
    "For this experiement, we should have both groups from the same city/region.\n",
    "\n",
    "We are interested in testing a hypotheses: whether the marketing message provided increase average number of purchases compeleted after selling per seller. Since the metrics are averages over iid sellers (assuming we randomized correctly), we know the corresponding distributions should be normal, a 2 sample z-test will suffice to determine if the difference in avg purchases completed is statistical significant.\n",
    "\n",
    "We need to consider experimental power. We need enough number of observations such that the minimal difference in a metric can be detected. This impacts the length of the experiment.\n",
    "\n",
    "For a risky experiment, we may not want to expose the whole population at once. If the traffic is high enough, we can often get away with a lower exposure rate and still satisfy a reasonable time to completion."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
